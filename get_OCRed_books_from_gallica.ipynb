{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8afe746-0d44-4c40-960a-a694b9b04ca1",
   "metadata": {},
   "source": [
    "# Getting OCR-ed books from gallica.bnf.fr\n",
    "\n",
    "The whole digital collection for various centuries is at https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-acces-par-periode?mode=desktop. Our focus is on the following collections:\n",
    "\n",
    "1. https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-du-xviiie-siecle?mode=desktop\n",
    "2. https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-du-xixe-siecle?mode=desktop\n",
    "3. https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-du-xxe-siecle?mode=desktop\n",
    "\n",
    "Our task is to download all OCR-ed books from that collection for three centuries. The problem is that the APIs (https://api.bnf.fr/api-gallica-de-recherche#/recherche and https://api.bnf.fr/fr/api-document-de-gallica#/texte%20brut/get__ark__texteBrut) do not provide search over collections.\n",
    "\n",
    "## Get all authors from the collection and the links to their pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23822145-7f68-4e9e-9ec7-225671728c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "urls = ['https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-du-xviiie-siecle?mode=desktop',\n",
    "        'https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-du-xixe-siecle?mode=desktop',\n",
    "        'https://gallica.bnf.fr/html/und/litteratures/les-classiques-de-la-litterature-du-xxe-siecle?mode=desktop']\n",
    "authors = []\n",
    "for url in urls:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    for link in soup.find_all(\"div\", {\"class\": \"titre\"}):\n",
    "        try:\n",
    "            authors.append( [link.a.get('href'), link.a.get('title')] )\n",
    "        except Exception:\n",
    "            pass\n",
    "len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7b882-ba01-4124-a0a2-a3ef15d1d796",
   "metadata": {},
   "source": [
    "## Get all links to all books of all authors, titles of books, contributors and license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b7f18-6b38-4045-925d-2c3ef2cfde49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_gallica(query, keywords, filters, startRecord=1):\n",
    "    url='https://gallica.bnf.fr/SRU'\n",
    "    params = {'operation': 'searchRetrieve',\n",
    "              'exactSearch': False,\n",
    "              'version': '1.2',\n",
    "              'query': query,\n",
    "              'collapsing': True,\n",
    "              'keywords': keywords,\n",
    "              'startRecord': startRecord,\n",
    "              'maximumRecords': 50,\n",
    "              'filter': filters,\n",
    "              }\n",
    "    try:\n",
    "        r = requests.get(url, params)\n",
    "        r.raise_for_status()\n",
    "    except Exception: # due to error 500 sometimes\n",
    "        r = requests.get(url, params)\n",
    "        r.raise_for_status()\n",
    "    return BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "def merge_pages_of_records(soup, link):\n",
    "    records = []\n",
    "    for record in soup.find_all(\"srw:record\"):\n",
    "        identifier = record.find('dc:identifier').text\n",
    "        title = record.find('dc:title').text\n",
    "        contributors = [s.text for s in record.find_all('dc:contributor')]\n",
    "        rights = [s.text for s in record.find_all('dc:rights')]\n",
    "        records.append([link, identifier, title, contributors, rights])\n",
    "    return records\n",
    "\n",
    "records = []\n",
    "errors = []\n",
    "for i, (link, title) in tqdm(enumerate(authors)):\n",
    "    if link.startswith('https://gallica.bnf.fr/ark:'):\n",
    "        records.append([link, link, title, [], []])\n",
    "    else:\n",
    "        parts_of_link = [str(s) for s in link.split('&')]\n",
    "        query = [s.replace('query=', '') for s in parts_of_link if s.startswith('query')]\n",
    "        filters = [s.replace('filter=', '') for s in parts_of_link if s.startswith('filter')]\n",
    "        keywords = [s.replace('keywords=', '') for s in parts_of_link if s.startswith('keywords')]\n",
    "        try:\n",
    "            soup = request_gallica(query, keywords, filters)\n",
    "            number_of_records = int(soup.find(\"srw:numberofrecords\").text)\n",
    "            records.extend( merge_pages_of_records(soup, link) )\n",
    "            pages = number_of_records // 50\n",
    "            if pages>0 and number_of_records!=50:\n",
    "                sRecord = 51\n",
    "                for page in range(1,pages+1):\n",
    "                    sRecord += 50 \n",
    "                    soup = request_gallica(query, keywords, filters, startRecord=sRecord)\n",
    "                    records.extend(merge_pages_of_records(soup, link))\n",
    "        except Exception:\n",
    "            errors.append([i, link, title, sRecord])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544e36a-b3d3-4d46-b3a8-6223b5ff8cd2",
   "metadata": {},
   "source": [
    "## Saving metadata and problematic cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbfa2a5-faab-4903-a5f6-e5cf7908db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(errors), len(records) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b88f5e-4aa7-43ac-b4df-8cd355581999",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for rec in records:\n",
    "    if rec[1].startswith('https://gallica.bnf.fr/ark'):\n",
    "        num += 1\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1218d459-b19a-4400-9576-7841b5c03bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"records.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['identifier', 'title', 'contributors', 'rights']) #'link', \n",
    "    writer.writerows(records)\n",
    "\n",
    "with open(\"errors.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['index', 'link', 'title']) # , 'sRecord'\n",
    "    writer.writerows(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f1749-5c24-492d-9005-efe153813a67",
   "metadata": {},
   "source": [
    "## Download all OCR-ed books into /data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de07e4-efb6-4d7f-ac80-2f975165b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rec in tqdm(records):\n",
    "    [link, url, title, contributors, license] = rec\n",
    "    if url.startswith('https://gallica.bnf.fr/ark'): \n",
    "        filename = url.replace('https://gallica.bnf.fr/', '').replace('/', '|')\n",
    "        url = url + '.texteBrut'\n",
    "        urllib.request.urlretrieve(url, '/Users/teddy/Documents/digitale_Romanistik/data/' + filename + '.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
